# Dockerfile for ScholarBot (Optional - for containerized deployment)
FROM python:3.11-slim

# Install system dependencies
RUN apt-get update && apt-get install -y \
    curl \
    wget \
    gcc \
    g++ \
    libmagic1 \
    && rm -rf /var/lib/apt/lists/*

# Install Ollama
RUN curl -fsSL https://ollama.com/install.sh | sh

# Set working directory
WORKDIR /app

# Copy requirements first for better caching
COPY requirements.txt .

# Install Python dependencies
RUN pip install --no-cache-dir -r requirements.txt

# Copy application code
COPY . .

# Create necessary directories
RUN mkdir -p data vectordb history temp

# Expose ports
EXPOSE 8501 11434

# Create startup script
RUN echo '#!/bin/bash\n\
# Start Ollama in background\n\
ollama serve &\n\
sleep 5\n\
\n\
# Pull required models if not present\n\
ollama list | grep -q "llama3.1:8b" || ollama pull llama3.1:8b &\n\
ollama list | grep -q "nomic-embed-text" || ollama pull nomic-embed-text &\n\
wait\n\
\n\
# Start ScholarBot\n\
streamlit run app.py --server.address 0.0.0.0\n\
' > start.sh && chmod +x start.sh

CMD ["./start.sh"]

# Docker Compose file (save as docker-compose.yml)
---
version: '3.8'

services:
  scholarbot:
    build: .
    ports:
      - "8501:8501"
      - "11434:11434"
    volumes:
      - ./data:/app/data
      - ./vectordb:/app/vectordb
      - ./history:/app/history
      - ollama_data:/root/.ollama
    environment:
      - PYTHONUNBUFFERED=1
    restart: unless-stopped

volumes:
  ollama_data:

# Usage:
# docker-compose up -d
# Access at http://localhost:8501